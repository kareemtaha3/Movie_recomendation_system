{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System - Data Exploration\n",
    "\n",
    "This notebook explores the movie dataset and user ratings to understand the data characteristics before building the neuro-fuzzy recommendation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Project paths\n",
    "PROJECT_DIR = Path().resolve().parents[0]\n",
    "RAW_DATA_DIR = PROJECT_DIR / 'data' / 'raw'\n",
    "\n",
    "print(f'Project directory: {PROJECT_DIR}')\n",
    "print(f'Raw data directory: {RAW_DATA_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the movie and ratings data from the raw data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data\n",
    "def load_data():\n",
    "    try:\n",
    "        movies_path = RAW_DATA_DIR / 'movies.csv'\n",
    "        ratings_path = RAW_DATA_DIR / 'ratings.csv'\n",
    "        \n",
    "        if not movies_path.exists() or not ratings_path.exists():\n",
    "            print(\"Raw data files not found. Please download the dataset first.\")\n",
    "            return None, None\n",
    "            \n",
    "        movies_df = pd.read_csv(movies_path)\n",
    "        ratings_df = pd.read_csv(ratings_path)\n",
    "        \n",
    "        print(f\"Loaded {len(movies_df)} movies and {len(ratings_df)} ratings\")\n",
    "        return movies_df, ratings_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Load the data\n",
    "movies_df, ratings_df = load_data()\n",
    "\n",
    "# Display the first few rows of each dataframe\n",
    "if movies_df is not None and ratings_df is not None:\n",
    "    print(\"\\nMovies dataframe:\")\n",
    "    display(movies_df.head())\n",
    "    \n",
    "    print(\"\\nRatings dataframe:\")\n",
    "    display(ratings_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "Examine the basic characteristics of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if movies_df is not None and ratings_df is not None:\n",
    "    # Movies dataframe info\n",
    "    print(\"\\nMovies dataframe info:\")\n",
    "    print(movies_df.info())\n",
    "    print(\"\\nMovies dataframe description:\")\n",
    "    print(movies_df.describe(include='all'))\n",
    "    \n",
    "    # Ratings dataframe info\n",
    "    print(\"\\nRatings dataframe info:\")\n",
    "    print(ratings_df.info())\n",
    "    print(\"\\nRatings dataframe description:\")\n",
    "    print(ratings_df.describe())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values in movies dataframe:\")\n",
    "    print(movies_df.isnull().sum())\n",
    "    \n",
    "    print(\"\\nMissing values in ratings dataframe:\")\n",
    "    print(ratings_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Analysis\n",
    "\n",
    "Analyze the movie dataset to understand the distribution of genres and release years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if movies_df is not None:\n",
    "    # Extract year from title\n",
    "    movies_df['year'] = movies_df['title'].str.extract(r'\\((\\d{4})\\)$')\n",
    "    movies_df['clean_title'] = movies_df['title'].str.replace(r'\\s*\\(\\d{4}\\)$', '', regex=True)\n",
    "    \n",
    "    # Convert year to numeric\n",
    "    movies_df['year'] = pd.to_numeric(movies_df['year'], errors='coerce')\n",
    "    \n",
    "    # Plot distribution of movie release years\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.histplot(movies_df['year'].dropna(), bins=50, kde=True)\n",
    "    plt.title('Distribution of Movie Release Years')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze genres\n",
    "    # Split the genres string into a list\n",
    "    movies_df['genres_list'] = movies_df['genres'].str.split('|')\n",
    "    \n",
    "    # Count genre occurrences\n",
    "    all_genres = []\n",
    "    for genres in movies_df['genres_list']:\n",
    "        if isinstance(genres, list):\n",
    "            all_genres.extend(genres)\n",
    "    \n",
    "    genre_counts = pd.Series(all_genres).value_counts()\n",
    "    \n",
    "    # Plot top genres\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x=genre_counts.index[:15], y=genre_counts.values[:15])\n",
    "    plt.title('Top 15 Movie Genres')\n",
    "    plt.xlabel('Genre')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings Analysis\n",
    "\n",
    "Analyze the ratings dataset to understand user behavior and rating patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ratings_df is not None:\n",
    "    # Distribution of ratings\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='rating', data=ratings_df)\n",
    "    plt.title('Distribution of Ratings')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate rating statistics per user\n",
    "    user_ratings = ratings_df.groupby('userId')['rating'].agg(['count', 'mean', 'std'])\n",
    "    \n",
    "    # Plot distribution of number of ratings per user\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(user_ratings['count'], bins=50, kde=True)\n",
    "    plt.title('Distribution of Number of Ratings per User')\n",
    "    plt.xlabel('Number of Ratings')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xscale('log')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot distribution of average rating per user\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(user_ratings['mean'], bins=50, kde=True)\n",
    "    plt.title('Distribution of Average Rating per User')\n",
    "    plt.xlabel('Average Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate rating statistics per movie\n",
    "    movie_ratings = ratings_df.groupby('movieId')['rating'].agg(['count', 'mean', 'std'])\n",
    "    \n",
    "    # Plot distribution of number of ratings per movie\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(movie_ratings['count'], bins=50, kde=True)\n",
    "    plt.title('Distribution of Number of Ratings per Movie')\n",
    "    plt.xlabel('Number of Ratings')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xscale('log')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot distribution of average rating per movie\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(movie_ratings['mean'], bins=50, kde=True)\n",
    "    plt.title('Distribution of Average Rating per Movie')\n",
    "    plt.xlabel('Average Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Item Interaction Analysis\n",
    "\n",
    "Analyze the interaction between users and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ratings_df is not None and movies_df is not None:\n",
    "    # Create a pivot table of user-item ratings\n",
    "    user_item_matrix = ratings_df.pivot(index='userId', columns='movieId', values='rating')\n",
    "    \n",
    "    # Calculate sparsity\n",
    "    sparsity = 1.0 - len(ratings_df) / (user_item_matrix.shape[0] * user_item_matrix.shape[1])\n",
    "    print(f\"Sparsity of the user-item matrix: {sparsity:.4f} ({sparsity*100:.2f}%)\")\n",
    "    \n",
    "    # Display a small sample of the user-item matrix\n",
    "    print(\"\\nSample of the user-item matrix (first 5 users, first 5 movies):\")\n",
    "    display(user_item_matrix.iloc[:5, :5])\n",
    "    \n",
    "    # Visualize the sparsity pattern\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.spy(user_item_matrix.iloc[:100, :100], precision=0.1, markersize=2)\n",
    "    plt.title('Sparsity Pattern (First 100 Users and Movies)')\n",
    "    plt.xlabel('Movie ID')\n",
    "    plt.ylabel('User ID')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Analysis\n",
    "\n",
    "Analyze the temporal patterns in the ratings data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ratings_df is not None:\n",
    "    # Convert timestamp to datetime\n",
    "    ratings_df['timestamp'] = pd.to_datetime(ratings_df['timestamp'], unit='s')\n",
    "    \n",
    "    # Extract time components\n",
    "    ratings_df['year'] = ratings_df['timestamp'].dt.year\n",
    "    ratings_df['month'] = ratings_df['timestamp'].dt.month\n",
    "    ratings_df['day'] = ratings_df['timestamp'].dt.day\n",
    "    ratings_df['hour'] = ratings_df['timestamp'].dt.hour\n",
    "    \n",
    "    # Plot ratings over time (by year)\n",
    "    yearly_ratings = ratings_df.groupby('year').size()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    yearly_ratings.plot(kind='bar')\n",
    "    plt.title('Number of Ratings by Year')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Ratings')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot average rating by year\n",
    "    yearly_avg_ratings = ratings_df.groupby('year')['rating'].mean()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    yearly_avg_ratings.plot(kind='line', marker='o')\n",
    "    plt.title('Average Rating by Year')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot ratings by hour of day\n",
    "    hourly_ratings = ratings_df.groupby('hour').size()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    hourly_ratings.plot(kind='bar')\n",
    "    plt.title('Number of Ratings by Hour of Day')\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Number of Ratings')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Preference Analysis\n",
    "\n",
    "Analyze user preferences for different movie genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ratings_df is not None and movies_df is not None:\n",
    "    # Merge ratings with movies to get genre information\n",
    "    ratings_with_genres = pd.merge(ratings_df, movies_df, on='movieId')\n",
    "    \n",
    "    # Create a dataframe with one row per movie-genre combination\n",
    "    genre_ratings = []\n",
    "    \n",
    "    for _, row in ratings_with_genres.iterrows():\n",
    "        genres = row['genres'].split('|')\n",
    "        for genre in genres:\n",
    "            genre_ratings.append({\n",
    "                'userId': row['userId'],\n",
    "                'movieId': row['movieId'],\n",
    "                'rating': row['rating'],\n",
    "                'genre': genre\n",
    "            })\n",
    "    \n",
    "    genre_ratings_df = pd.DataFrame(genre_ratings)\n",
    "    \n",
    "    # Calculate average rating by genre\n",
    "    genre_avg_ratings = genre_ratings_df.groupby('genre')['rating'].agg(['mean', 'count'])\n",
    "    genre_avg_ratings = genre_avg_ratings.sort_values('count', ascending=False)\n",
    "    \n",
    "    # Plot average rating by genre (for top genres)\n",
    "    top_genres = genre_avg_ratings.head(15).index\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x=top_genres, y=genre_avg_ratings.loc[top_genres, 'mean'])\n",
    "    plt.title('Average Rating by Genre (Top 15 Genres)')\n",
    "    plt.xlabel('Genre')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot number of ratings by genre\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x=top_genres, y=genre_avg_ratings.loc[top_genres, 'count'])\n",
    "    plt.title('Number of Ratings by Genre (Top 15 Genres)')\n",
    "    plt.xlabel('Genre')\n",
    "    plt.ylabel('Number of Ratings')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "\n",
    "Analyze correlations between movie features and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ratings_df is not None and movies_df is not None:\n",
    "    # Merge ratings with movies\n",
    "    merged_df = pd.merge(ratings_df, movies_df, on='movieId')\n",
    "    \n",
    "    # Calculate correlation between movie year and rating\n",
    "    if 'year' in merged_df.columns:\n",
    "        year_rating_corr = merged_df['year'].corr(merged_df['rating'])\n",
    "        print(f\"Correlation between movie year and rating: {year_rating_corr:.4f}\")\n",
    "        \n",
    "        # Plot year vs. rating\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(x='year', y='rating', data=merged_df.sample(10000))\n",
    "        plt.title('Rating Distribution by Movie Year')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Rating')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Calculate correlation between number of ratings and average rating\n",
    "    movie_stats = merged_df.groupby('movieId').agg({\n",
    "        'rating': ['count', 'mean']\n",
    "    })\n",
    "    movie_stats.columns = ['rating_count', 'rating_mean']\n",
    "    \n",
    "    count_rating_corr = movie_stats['rating_count'].corr(movie_stats['rating_mean'])\n",
    "    print(f\"Correlation between number of ratings and average rating: {count_rating_corr:.4f}\")\n",
    "    \n",
    "    # Plot number of ratings vs. average rating\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(movie_stats['rating_count'], movie_stats['rating_mean'], alpha=0.5)\n",
    "    plt.title('Average Rating vs. Number of Ratings')\n",
    "    plt.xlabel('Number of Ratings')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Summarize the key findings from the data exploration and discuss implications for the recommendation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the exploratory data analysis, we can draw the following conclusions:\n",
    "\n",
    "1. **Data Characteristics**:\n",
    "   - The dataset contains a large number of movies and ratings\n",
    "   - The user-item matrix is highly sparse, which is typical for recommendation systems\n",
    "   - There is a wide range of movie release years and genres\n",
    "\n",
    "2. **Rating Patterns**:\n",
    "   - Ratings are not uniformly distributed; some ratings are more common than others\n",
    "   - Users have varying levels of activity, with some users rating many movies and others rating only a few\n",
    "   - Movies also have varying levels of popularity, with some movies receiving many ratings and others receiving few\n",
    "\n",
    "3. **Temporal Patterns**:\n",
    "   - Rating activity varies over time, with certain years showing more activity than others\n",
    "   - There may be hourly patterns in rating behavior\n",
    "\n",
    "4. **Genre Preferences**:\n",
    "   - Different genres have different average ratings\n",
    "   - Some genres are more popular (receive more ratings) than others\n",
    "\n",
    "5. **Correlations**:\n",
    "   - There may be correlations between movie features (e.g., year, genre) and ratings\n",
    "   - There may be correlations between popularity (number of ratings) and average rating\n",
    "\n",
    "**Implications for the Neuro-Fuzzy Recommendation Model**:\n",
    "\n",
    "1. **Feature Engineering**:\n",
    "   - We should include movie features such as genre and release year\n",
    "   - We may want to include user features such as activity level and rating patterns\n",
    "   - Temporal features may also be useful\n",
    "\n",
    "2. **Model Design**:\n",
    "   - The model should handle the high sparsity of the user-item matrix\n",
    "   - We may want to use a hybrid approach that combines collaborative filtering with content-based filtering\n",
    "   - The fuzzy component can help capture the uncertainty in user preferences\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - We should evaluate the model on different user segments (e.g., active vs. inactive users)\n",
    "   - We should evaluate the model on different movie segments (e.g., popular vs. unpopular movies)\n",
    "   - We should consider both accuracy metrics (e.g., RMSE) and ranking metrics (e.g., precision, recall)\n",
    "\n",
    "Next steps include preprocessing the data, engineering features, and building the neuro-fuzzy recommendation model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}